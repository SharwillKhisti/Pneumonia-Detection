import streamlit as st
import torch
import torchvision.transforms as transforms
from PIL import Image
import os
import pandas as pd
from models import get_model
from utils import load_checkpoint, generate_gradcam, get_target_layer

# ğŸ“ Checkpoint directory
CHECKPOINT_DIR = os.path.join("..", "checkpoints")

# âœ… Available models and checkpoints
MODEL_CHECKPOINTS = {
    "resnet18_CURLM_phase0": "resnet18_CURLM_phase0.pth",
    "resnet18_CURLM_phase1": "resnet18_CURLM_phase1.pth",
    "resnet18_DIRECT_phase1": "resnet18_DIRECT_phase1.pth",
    "resnet50_phase0": "resnet50_phase0.pth",
    "resnet50_phase1": "resnet50_phase1.pth",
    "densenet121_phase0": "densenet121_phase0.pth",
    "densenet121_phase1": "densenet121_phase1.pth"
}

# ğŸ§  Class mapping
CLASS_MAP = {0: "Normal", 1: "Pneumonia"}

# ğŸ“Š Model performance stats
def get_model_stats():
    return pd.DataFrame({
        "Model": [
            "ResNet18 CURLM", "ResNet18 CURLM", "ResNet18 DIRECT",
            "ResNet50", "ResNet50", "DenseNet121", "DenseNet121"
        ],
        "Phase": ["0", "1", "1", "0", "1", "0", "1"],
        "Accuracy (%)": [97.94, 98.51, 96.68, 97.82, 97.02, 98.63, 98.40],
        "Precision": [0.96, 0.97, 0.94, 0.96, 0.94, 0.97, 0.97],
        "Recall": [0.96, 0.97, 0.94, 0.95, 0.95, 0.98, 0.97],
        "F1-score": [0.96, 0.97, 0.94, 0.96, 0.94, 0.97, 0.97]
    })

# ğŸ” Prediction logic
def predict(model, image_tensor):
    with torch.no_grad():
        output = model(image_tensor)
        probs = torch.softmax(output, dim=1)
        confidence, pred_class = torch.max(probs, dim=1)
        return CLASS_MAP[pred_class.item()], confidence.item(), pred_class.item()

# ğŸ§  Explanation logic
def generate_explanation(prediction, confidence, checkpoint_name):
    if prediction == "Pneumonia":
        return f"""
        The model has classified this image as **Pneumonia** with **{confidence*100:.2f}%** confidence.

        ğŸ” **Why?**  
        The Grad-CAM overlay shows intense activation in regions typically associated with pulmonary infiltrates â€” such as the lower lobes and perihilar areas. These red-hot zones suggest the model is focusing on abnormal opacities, which are common indicators of pneumonia.

        ğŸ§ª **Model Used:** `{checkpoint_name}`  
        ğŸ§­ **Interpretation:** The model is likely detecting texture irregularities, asymmetry, or density shifts in lung fields that deviate from healthy patterns.
        """
    else:
        return f"""
        The model has classified this image as **Normal** with **{confidence*100:.2f}%** confidence.

        ğŸ” **Why?**  
        The Grad-CAM overlay shows minimal activation, indicating the model did not detect significant anomalies. The attention is diffuse or centered in non-critical zones, suggesting a lack of pathological features.

        ğŸ§ª **Model Used:** `{checkpoint_name}`  
        ğŸ§­ **Interpretation:** The model sees balanced lung fields, clear costophrenic angles, and no signs of consolidation or abnormal texture.
        """

# ğŸ–¼ï¸ Image preprocessing
def preprocess_image(uploaded_file):
    image = Image.open(uploaded_file).convert("RGB")
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    return transform(image).unsqueeze(0), image.resize((224, 224))

# ğŸ§  Streamlit UI
st.set_page_config(page_title="Pneumonia Detection", layout="centered")
st.title("ğŸ« Pneumonia Detection Dashboard")
st.markdown("Upload a chest X-ray and select a model to view prediction, Grad-CAM, and performance comparison.")

uploaded_file = st.file_uploader("ğŸ“¤ Upload Chest X-ray", type=["png", "jpg", "jpeg"])
selected_model_key = st.selectbox("ğŸ§  Choose Model Checkpoint", list(MODEL_CHECKPOINTS.keys()))

if uploaded_file and selected_model_key:
    image_tensor, resized_image = preprocess_image(uploaded_file)
    checkpoint_path = os.path.join(CHECKPOINT_DIR, MODEL_CHECKPOINTS[selected_model_key])
    base_model_name = selected_model_key.split("_")[0]

    # ğŸ”§ Load model
    model = get_model(base_model_name, num_classes=2)
    model = load_checkpoint(model, checkpoint_path, device="cpu")
    model.eval()

    # ğŸ” Predict
    prediction, confidence, class_idx = predict(model, image_tensor)
    st.subheader(f"ğŸ©º Prediction: **{prediction}** ({confidence*100:.2f}%)")

    # ğŸ”¥ Grad-CAM
    target_layer = get_target_layer(model, base_model_name)
    gradcam_img = generate_gradcam(model, image_tensor.squeeze(0), target_layer, device="cpu", class_idx=class_idx)

    # ğŸ§  Explanation
    explanation = generate_explanation(prediction, confidence, selected_model_key)

    # ğŸ–¼ï¸ Display Images Side-by-Side
    col1, col2 = st.columns(2)
    with col1:
        st.image(resized_image, caption="ğŸ–¼ï¸ Original X-Ray", use_container_width=True)
    with col2:
        st.image(gradcam_img, caption="ğŸ”¥ Grad-CAM Overlay", use_container_width=True)

    # ğŸ§  Display Explanation
    st.markdown("### ğŸ§  AI Explainer")
    st.markdown(explanation)

    # ğŸ“Š Model Comparison Table
    st.markdown("---")
    st.subheader("ğŸ“Š Model Performance Comparison")
    st.dataframe(get_model_stats(), use_container_width=True)